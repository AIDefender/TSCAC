algo: "wide_deep"
# state_dim: 27
state_dim: 1044
action_dim: 1
reward_dim: 7
response_dim: 7
max_action: 150
max_buffer_size: 5000000
discount: 0.99
tau: 0.001

max_steps: 160000
bc_steps: 500000
# max_steps: 500
test_every: 10
log_every: 10
save_every: 10000

batch_size: 512
small_buffer: False
train_sl: False

save_model: True
use_tensorboard: True
bc_loss_coeff: 0.01

reward_service: 0.1
reward_business: 0.1
reward_cleanliness: 0.1
reward_check_in: 0.1
reward_value: 0.1
reward_rooms: 0.1
reward_location: 0.1
reward_overall: 10


reward_click: 0.1
reward_like: 0.1
reward_follow: 0.1
reward_comment: 0.1
reward_forward: 0.1
reward_hate: -0.1
reward_play_time: 30

behavior_onehot: True
